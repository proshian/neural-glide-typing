{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TODO\n",
    "\n",
    "1. remove dropout from exported programs\n",
    "2. вероятно нужно сделать модули FullEncoder \n",
    "3. проверить, игнорируются поля модели, которые не используются в forward (например, есть ли разница между текущей инмплементацией `Decode` и имплементацией, где вся модель хранится как удинственное поле Decode) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Dict, Union, Tuple\n",
    "import os\n",
    "import array\n",
    "\n",
    "import torch\n",
    "from torch import Tensor\n",
    "from torch.export import export, ExportedProgram, Dim\n",
    "from executorch.exir import EdgeProgramManager, to_edge, to_edge_transform_and_lower\n",
    "from executorch.exir.backend.backend_api import LoweredBackendModule, to_backend\n",
    "from executorch.backends.xnnpack.partition.xnnpack_partitioner import XnnpackPartitioner\n",
    "\n",
    "from model import MODEL_GETTERS_DICT\n",
    "from feature_extractors import get_val_transform\n",
    "from ns_tokenizers import CharLevelTokenizerv2, KeyboardTokenizerv1\n",
    "from word_generators_v2 import BeamGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_prefix(s: str, prefix: str) -> str:\n",
    "    if s.startswith(prefix):\n",
    "        s = s[len(prefix):]\n",
    "    return s\n",
    "\n",
    "\n",
    "def get_state_dict_from_checkpoint(ckpt: dict) -> Dict[str, torch.Tensor]:\n",
    "    return {remove_prefix(k, 'model.'): v for k, v in ckpt['state_dict'].items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COMMAND LINE ARGUMENTS EMULATION\n",
    "\n",
    "MODEL_NAME = 'v3_nearest_and_traj_transformer_bigger'\n",
    "CHECKPOINT_ROOT_PATH = '../../../checkpoints_for_executorch/my_nearest_features/'\n",
    "CHECKPOINT_PATH = os.path.join(CHECKPOINT_ROOT_PATH, 'v3_nearest_and_traj_transformer_bigger-default--epoch=73-val_loss=0.444-val_word_level_accuracy=0.872.ckpt')\n",
    "TRANSFORM_NAME =  \"traj_feats_and_nearest_key\"\n",
    "\n",
    "DATA_ROOT = '../data/data_separated_grid'\n",
    "\n",
    "GRIDNAME_TO_GRID_PATH = os.path.join(DATA_ROOT, \"gridname_to_grid.json\")\n",
    "voc_path=os.path.join(DATA_ROOT, \"voc.txt\")\n",
    "char_tokenizer = CharLevelTokenizerv2(voc_path)\n",
    "kb_tokenizer = KeyboardTokenizerv1()\n",
    "\n",
    "USE_TIME = False\n",
    "USE_VELOCITY = True\n",
    "USE_ACCELERATION = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/proshian/Documents/executorch_test_examples/executorch_examples_venv/lib/python3.12/site-packages/torch/nn/modules/transformer.py:379: UserWarning: enable_nested_tensor is True, but self.use_nested_tensor is False because encoder_layer.self_attn.batch_first was not True(use batch_first for better inference performance)\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_dict = get_state_dict_from_checkpoint(\n",
    "    torch.load(CHECKPOINT_PATH, map_location='cpu', weights_only=True))\n",
    "\n",
    "model = MODEL_GETTERS_DICT[MODEL_NAME]().eval()\n",
    "model.load_state_dict(state_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _prepare_encoder_input(encoder_in: Union[Tensor, Tuple[Tensor, Tensor]], \n",
    "                           device: str, batch_first: bool\n",
    "                           ) -> Tuple[Tensor, Tensor]:\n",
    "    is_tensor = None\n",
    "    if isinstance(encoder_in, Tensor):\n",
    "        is_tensor = True\n",
    "        encoder_in = [encoder_in]\n",
    "    else:\n",
    "        is_tensor = False\n",
    "\n",
    "    encoder_in = [el.unsqueeze(0) if batch_first else el.unsqueeze(1) for el in encoder_in]\n",
    "    encoder_in = [el.to(device) for el in encoder_in]\n",
    "\n",
    "    return encoder_in[0] if is_tensor else encoder_in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "RAW_DATASET_ITEM_EXAMPLE = (\n",
    "    array.array('h', [567, 567, 507, 424, 380, 348, 337, 332, 330, 329, 327, 326, 326]),\n",
    "    array.array('h', [66, 66, 101, 161, 196, 230, 240, 245, 247, 249, 251, 251, 251]),\n",
    "    array.array('h', [0, 3, 24, 52, 75, 90, 106, 129, 145, 161, 177, 195, 209]),\n",
    "    'default',\n",
    "    'на')\n",
    "\n",
    "GRIDNAME_TO_GRID_PATH = '../data/data_separated_grid/gridname_to_grid.json'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accumulating out-of-bounds coordinates...\n",
      "augmenting gname_to_out_of_bounds\n"
     ]
    }
   ],
   "source": [
    "transform = get_val_transform(\n",
    "    gridname_to_grid_path=GRIDNAME_TO_GRID_PATH,\n",
    "    grid_names=['default'],\n",
    "    transform_name=TRANSFORM_NAME,\n",
    "    char_tokenizer=char_tokenizer,\n",
    "    uniform_noise_range=0,\n",
    "    include_time=USE_TIME,\n",
    "    include_velocities=USE_VELOCITY,\n",
    "    include_accelerations=USE_ACCELERATION,\n",
    "    dist_weights_func=None,  # Fill if weighted version is used\n",
    "    ds_paths_list=[],\n",
    ")\n",
    "\n",
    "\n",
    "(encoder_in, decoder_in), decoder_out_target = transform(RAW_DATASET_ITEM_EXAMPLE)\n",
    "encoder_in = _prepare_encoder_input(encoder_in, 'cpu', batch_first=False)\n",
    "if isinstance(encoder_in, list):\n",
    "    encoder_in = tuple(encoder_in)\n",
    "decoder_in = decoder_in.unsqueeze(1).to(torch.int32)\n",
    "\n",
    "encoded = model.encode(encoder_in, None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Get data manually\n",
    "# SWIPE_LENGTH = 13\n",
    "# BATCH_SIZE = 1\n",
    "# NUM_TRAJ_FEATS = 6\n",
    "# OUT_SEQ_LEN = 3\n",
    "\n",
    "# sample_kb_key_ids = torch.ones((SWIPE_LENGTH, BATCH_SIZE), dtype=torch.int32)\n",
    "# sample_traj_feats = torch.ones((SWIPE_LENGTH, BATCH_SIZE, NUM_TRAJ_FEATS), dtype=torch.float32)\n",
    "# encoder_in = (sample_traj_feats, sample_kb_key_ids)\n",
    "# decoder_in = torch.ones((OUT_SEQ_LEN, BATCH_SIZE), dtype=torch.int32)\n",
    "# encoded = model.encode(\n",
    "#     encoder_in, \n",
    "#     None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Encode(torch.nn.Module):\n",
    "    def __init__(self, model) -> None:\n",
    "        super().__init__()\n",
    "        self.enc_in_emb_model = model.enc_in_emb_model\n",
    "        self.encoder = model.encoder\n",
    "\n",
    "    def forward(self, encoder_in):\n",
    "        x = self.enc_in_emb_model(encoder_in)\n",
    "        result = self.encoder(x, src_key_padding_mask = None)\n",
    "        return result\n",
    "\n",
    "\n",
    "class Decode(torch.nn.Module):\n",
    "    def __init__(self, model) -> None:\n",
    "        super().__init__()\n",
    "        self.dec_in_emb_model = model.dec_in_emb_model\n",
    "        self.decoder = model.decoder\n",
    "        self._get_mask = model._get_mask\n",
    "        self.out = model.out\n",
    "\n",
    "    def forward(self, decoder_in, x_encoded):\n",
    "        y = self.dec_in_emb_model(decoder_in)\n",
    "        tgt_mask = self._get_mask(y.size(0))  # = self.causal_mask[y.size(0):, y.size(0):]\n",
    "        dec_out = self.decoder(\n",
    "            y, x_encoded, tgt_mask=tgt_mask, \n",
    "            memory_key_padding_mask=None, \n",
    "            tgt_key_padding_mask=None,\n",
    "            tgt_is_causal=True)\n",
    "        return self.out(dec_out)\n",
    "    \n",
    "\n",
    "MAX_SWIPE_LEN = 299\n",
    "MAX_WORD_LEN = 35\n",
    "dim_swipe_seq = Dim(\"dim_swipe_seq\", min=1, max=MAX_SWIPE_LEN)\n",
    "dim_char_seq = Dim(\"dim_char_seq\", min=1, max=MAX_WORD_LEN)\n",
    "\n",
    "encoder_dynamic_shapes = {\"encoder_in\": ({0: dim_swipe_seq}, {0: dim_swipe_seq})}\n",
    "decoder_dynamic_shapes = {\n",
    "    \"x_encoded\": {0: dim_swipe_seq},\n",
    "    \"decoder_in\": {0: dim_char_seq}\n",
    "}\n",
    "\n",
    "aten_encode: ExportedProgram = export(Encode(model).eval(), (encoder_in,), dynamic_shapes=encoder_dynamic_shapes)\n",
    "aten_decode: ExportedProgram = export(Decode(model).eval(), (decoder_in, encoded), dynamic_shapes=decoder_dynamic_shapes)\n",
    "\n",
    "edge_xnnpack: EdgeProgramManager = to_edge_transform_and_lower(\n",
    "    {\"encode\": aten_encode, \"decode\": aten_decode},\n",
    "    partitioner=[XnnpackPartitioner()],\n",
    ")\n",
    "\n",
    "exec_prog_xnnpack = edge_xnnpack.to_executorch()\n",
    "\n",
    "with open(\"xnnpack_my_nearest_feats.pte\", \"wb\") as file:\n",
    "    exec_prog_xnnpack.write_to_file(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "edge_program = to_edge({\"encode\": aten_encode, \"decode\": aten_decode})\n",
    "\n",
    "executorch_program = edge_program.to_executorch()\n",
    "\n",
    "with open(\"raw_my_nearest_feats.pte\", \"wb\") as file:\n",
    "    file.write(executorch_program.buffer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(aten_encode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print(exec_prog_xnnpack.exported_program('encode'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exec_prog_xnnpack.exported_program('encode').module()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "executorch_examples_venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
